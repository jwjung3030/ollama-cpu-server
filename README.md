# Ollama CPU Server

ì´ ì €ì¥ì†ŒëŠ” **[Ollama](https://github.com/ollama/ollama)** ëŸ°íƒ€ì„ ìœ„ì—ì„œ **Google Gemma 3** ëª¨ë¸ì„ CPU í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ì—¬  
ê°„ë‹¨í•œ REST APIë¥¼ êµ¬ì¶•í•˜ëŠ” ì˜ˆì œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ íŠ¹ì§•
- **CPU ê¸°ë°˜ ì‹¤í–‰**: GPU ì—†ì´ë„ Gemma 3 ëª¨ë¸ êµ¬ë™ ê°€ëŠ¥ (ëŠë¦´ ìˆ˜ ìˆìŒ).
- **ê°„ë‹¨í•œ ë°°í¬**: `docker-compose up` ë§Œìœ¼ë¡œ ì„œë²„ ì‹¤í–‰.
- **REST API ì§€ì›**: `curl` ë˜ëŠ” ë‹¤ë¥¸ í´ë¼ì´ì–¸íŠ¸ë¡œ ë²ˆì—­ ìš”ì²­ ê°€ëŠ¥.
---

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone -b feature/ollama-test-client --single-branch https://github.com/jwjung3030/ollama-cpu-server.git
cd ollama-cpu-server

```

### ì‹¤í–‰ íŒ¨í„´

```bash
1) ë‘˜ ë‹¤ ì¼œì„œ êµì°¨ ì ‘ì† í…ŒìŠ¤íŠ¸ (ê¶Œì¥)
docker compose --profile server --profile test up -d --build
docker exec -it ollama ollama pull gemma3:4b
docker exec -it ollama-test python /app/translate.py "ê°•ì•„ì§€ê°€ ì”ë””ë°­ì„ ë›°ì–´ë‹¤ë‹Œë‹¤."

2) ì„œë²„ë§Œ ìš´ì˜(ê°œë°œ/ë°°í¬ìš©)
docker compose --profile server up -d
# í•„ìš” ì‹œ í˜¸ìŠ¤íŠ¸ì—ì„œ curlë¡œ ì ê²€
curl -s http://localhost:11434/api/tags


3) í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆë§Œ (ì™¸ë¶€/ê³µìš© Ollama ì„œë²„ì— ë¶™ì¼ ë•Œ)
# ê³µìš© ì„œë²„ê°€ 10.0.0.5:11434 ë¼ë©´
docker compose --profile test run --rm \
  -e OLLAMA_HOST=http://10.0.0.5:11434 \
  -e OLLAMA_MODEL=gemma3:4b \
  ollama-test python /app/translate.py "â€¦ë¬¸ì¥â€¦"

```
